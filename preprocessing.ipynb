{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569237b5-267a-4eae-b70f-a64720989dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_markdown_files(src_dir, dest_dir):\n",
    "    \"\"\"递归地将所有子文件夹中的 Markdown 文件复制到目标目录\"\"\"\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)  # 如果目标目录不存在，则创建\n",
    "\n",
    "    # 遍历源目录及其子文件夹\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):  # 只处理 .md 文件\n",
    "                # 构造源文件路径\n",
    "                src_file = os.path.join(root, file)\n",
    "                # 构造目标文件路径\n",
    "                dest_file = os.path.join(dest_dir, file)\n",
    "                # 直接复制文件（如果目标文件存在，则会覆盖）\n",
    "                shutil.copy(src_file, dest_file)\n",
    "                print(f\"复制文件: {src_file} 到 {dest_file}\")\n",
    "\n",
    "# 使用示例\n",
    "src_directory = \"outputs2/\"  # 源目录路径\n",
    "dest_directory = \"all_md/\"  # 目标目录路径\n",
    "\n",
    "#copy_markdown_files(src_directory, dest_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e594ac3c-c8d4-4a81-800e-63e41c23e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm import tqdm  # 进度条库\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header\")\n",
    "]\n",
    "\n",
    "def process_markdown_file(file_path):\n",
    "    \"\"\"处理单个 Markdown 文件，返回 result1 和 result2\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            markdown_content = file.read()\n",
    "\n",
    "        markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "        chunks = markdown_splitter.split_text(markdown_content)\n",
    "        \n",
    "        header_key = [chunks[i].metadata['Header'].lower() for i in range(1,len(chunks))]\n",
    "        index_1 = header_key.index('introduction')+1 if 'introduction' in header_key else None\n",
    "        index_1 = index_1 if index_1 else header_key.index('background')+1 if 'background' in header_key else None\n",
    "        index_2 = header_key.index('discussion') if 'discussion' in header_key else None\n",
    "        title = chunks[0].metadata['Header'] if chunks[0].metadata else chunks[1].metadata['Header'] \n",
    "\n",
    "        results1 = {\n",
    "            \"text\": chunks[index_1].page_content if index_1 is not None else ' ',\n",
    "            \"meta\": {\"title\": title, \"name\": file_path.split('/')[1], \"type\": \"introduction\"}\n",
    "        }\n",
    "        results2 = {\n",
    "            \"text\": chunks[index_2].page_content if index_2 is not None else ' ',\n",
    "            \"meta\": {\"title\": title, \"name\": file_path.split('/')[1], \"type\": \"discussion\"}\n",
    "        }\n",
    "        \n",
    "        return results1, results2\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def write_to_jsonl(results, output_file):\n",
    "    \"\"\"将结果写入 JSONL 文件\"\"\"\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as file:\n",
    "        for result in results:\n",
    "            json.dump(result, file, ensure_ascii=False)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "def worker(args):\n",
    "    \"\"\"工作进程函数，将结果返回\"\"\"\n",
    "    file_path, result_list1, result_list2 = args\n",
    "    result1, result2 = process_markdown_file(file_path)\n",
    "    if result1 and result2:\n",
    "        result_list1.append(result1)\n",
    "        result_list2.append(result2)\n",
    "\n",
    "def process_files_in_parallel(input_dir, output_file1, output_file2, num_workers=4):\n",
    "    \"\"\"并行处理文件夹中的 Markdown 文件，分别写入两个 JSONL 文件\"\"\"\n",
    "    # 获取所有 Markdown 文件路径\n",
    "    markdown_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".md\")]\n",
    "\n",
    "    # 使用 Manager 创建共享列表\n",
    "    with Manager() as manager:\n",
    "        result_list1 = manager.list()\n",
    "        result_list2 = manager.list()\n",
    "        \n",
    "        # 创建进程池\n",
    "        with Pool(processes=num_workers) as pool:\n",
    "            # 使用 tqdm 包裹任务以显示进度条\n",
    "            with tqdm(total=len(markdown_files), desc=\"Processing files\") as pbar:\n",
    "                for _ in pool.imap_unordered(worker, [(f, result_list1, result_list2) for f in markdown_files]):\n",
    "                    pbar.update()\n",
    "        \n",
    "        # 将结果写入 JSONL 文件\n",
    "        write_to_jsonl(result_list1, output_file1)\n",
    "        write_to_jsonl(result_list2, output_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d338321-42b8-4656-90de-1f90f52d13a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   6%|█▏                 | 1877/30242 [00:08<02:03, 229.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file all_md/oskarsson2018.md: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  15%|██▊                | 4423/30242 [00:19<01:54, 224.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file all_md/jackson2017.md: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  42%|███████▍          | 12568/30242 [00:51<01:01, 289.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file all_md/decastro2018.md: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  58%|██████████▍       | 17638/30242 [01:13<00:56, 224.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file all_md/bailey2014.md: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  62%|███████████▏      | 18761/30242 [01:18<00:49, 229.75it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_directory = 'all_md/'\n",
    "    output_jsonl1 = 'introduction.jsonl'\n",
    "    output_jsonl2 = 'discussion.jsonl'\n",
    "    \n",
    "    process_files_in_parallel(input_directory, output_jsonl1, output_jsonl2, num_workers=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
